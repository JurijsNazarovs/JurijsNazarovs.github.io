---
---
@inproceedings{img2gif,
    abbr={AI4CC, CVPR},
    %teaser={/publications/me_ode2.pdf},
    %teaser={/publications/uncertainty_with_rf/teaser.pdf},
    teaser={/publications/wnode/teaser.gif},
    title = {Image2Gif: Generating Continuous Realistic Animations with Warping NODEs},
    author = {Nazarovs, Jurijs and Huang, Zhichun},
    abstract = {   Generating smooth animations from a limited number of sequential observations has a number of applications in vision. For example, it can be used to increase number of frames per second, or generating a new trajectory only based on first and last frames, e.g. a motion of face emotions. Despite the discrete observed data (frames), the problem of generating a new trajectory is a continues problem. In addition, to be perceptually realistic, the domain of an image should not alter drastically through the trajectory of changes. In this paper, we propose a new framework, Warping Neural ODE, for generating a smooth animation (video frame interpolation) in a continuous manner, given two ("farther apart") frames, denoting the start and the end of the animation. The key feature of our framework is utilizing the continuous spatial transformation of the image based on the vector field, derived from a system of differential equations. This allows us to achieve the smoothness and the realism of an animation with infinitely small time steps between the frames. We show the application of our work in generating an animation given two frames, in different training settings, including Generative Adversarial Network (GAN) and with L-2 loss.},
  year = {2022},
  //confname={AI4CC, CVPR},
  //acceptrate={25},
  month = {April},
  arxiv={2205.04519},
  //pdf={https://openaccess.thecvf.com/content/CVPR2022/papers/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.pdf},
  //supp={adios-icml16-supp.pdf},
  poster={/publications/wnode/poster.pdf},
  //video={https://youtu.be/WJquexM8E38},
  code={https://github.com/JurijsNazarovs/warping_node},

}


@inproceedings{uncertrf,
    abbr={CVPR},
    %teaser={/publications/me_ode2.pdf},
    %teaser={/publications/uncertainty_with_rf/teaser.pdf},
    teaser={/publications/uncertainty_with_rf/rf_1slide.png},
    title = {Understanding Uncertainty Maps in Vision With Statistical Testing},
    author = {Nazarovs, Jurijs and Huang, Zhichun and  Tasneeyapant, Songwong  and Chakraborty, Rudrasis and Singh, Vikas},
    abstract = {   Quantitative descriptions of confidence intervals and uncertainties of the predictions of a model are needed in many applications in vision and machine learning. Mechanisms that enable this for deep neural network (DNN) models are slowly becoming available, and occasionally, being integrated within production systems. But the literature is sparse in terms of how to perform statistical tests with the uncertainties produced by these overparameterized models. For two models with a similar accuracy profile, is the former model's uncertainty behavior better in a statistically significant sense compared to the second model? For high resolution images, performing hypothesis tests to generate meaningful actionable information (say, at a user specified significance level 0.05) is difficult but needed in both mission critical settings and elsewhere. In this paper, specifically for uncertainties defined on images, we show how revisiting results from Random Field theory (RFT) when paired with DNN tools (to get around computational hurdles) leads to efficient frameworks that can provide a hypothesis test capabilities, not otherwise available, for uncertainty maps from models used in many vision tasks. We show via many different experiments the viability of this framework.},
  year = {2022},
  //confname={Thirty-seventh Conference on Uncertainty in Artificial IntelligenceCVPR},
  acceptrate={25},
  month = {March},
  //arxiv={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  //pdf={/publications/meode/main.pdf},
  pdf={https://openaccess.thecvf.com/content/CVPR2022/papers/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.pdf},
  //supp={adios-icml16-supp.pdf},
  poster={/publications/uncertainty_with_rf/poster.pdf},
  video={https://youtu.be/WJquexM8E38},
  code={https://github.com/JurijsNazarovs/uncertainty_with_rf},

}

@inproceedings{radspslab,
    abbr={arXiv},
    teaser={/publications/radial_spikeslab/teaser.pdf},
    title = {Radial Spike and Slab Bayesian Neural Networks for Sparse Data in Ransomware Attacks},
    author = {Nazarovs, Jurijs and Stokes, Jack W. and Turcotte, Melissa and  Carroll, Justin and  Grady, Itai},
    abstract = {   },
  year = {2022},
  //confname={AI4CC, CVPR},
  //acceptrate={25},
  month = {April},
  arxiv={2205.14759},
  //pdf={https://openaccess.thecvf.com/content/CVPR2022/papers/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.pdf},
  //supp={adios-icml16-supp.pdf},
  //poster={/publications/wnode/poster.pdf},
  //video={https://youtu.be/WJquexM8E38},
  //code={https://github.com/JurijsNazarovs/panel_me_ode},

}



@inproceedings{ordinquadr,
    abbr={arXiv},
    %teaser={/publications/me_ode2.pdf},
    teaser={/publications/ordinal-quadruplet/ordin_quadr.gif},
    title = {Ordinal-Quadruplet: Retrieval of Missing Classes in Ordinal Time Series},
    author = {Nazarovs, Jurijs and Lumezanu, Cristian and  Ren, Qianying  and Chen, Yuncong and Mizoguchi, Takehiko and Song, Dongjin and Chen, Haifeng},
    %author = {Jurijs,  Nazarovs and, Cristian Lumezanu, Qianying Ren, Yuncong Chen, Takehiko Mizoguchi, Dongjin Song, Haifeng Chen},
    abstract = {In this paper, we propose an ordered time series classification framework that is robust against missing classes in the training data, i.e., during testing we can prescribe classes that are missing during training. This framework relies on two main components: (1) our newly proposed ordinal-quadruplet loss, which forces the model to learn latent representation while preserving the ordinal relation among labels, (2) testing procedure, which utilizes the property of latent representation (order preservation). We conduct experiments based on real world multivariate time series data and show the significant improvement in the prediction of missing labels even with 40\% of the classes are missing from training. Compared with the well-known triplet loss optimization augmented with interpolation for missing information, in some cases, we nearly double the accuracy.},
  year = {2022},
  //confname={Thirty-seventh Conference on Uncertainty in Artificial Intelligence},
  //acceptrate={26},
  //month = {May},
  arxiv={2201.09907},
  //pdf={/publications/meode/main.pdf},
  //supp={adios-icml16-supp.pdf},
  //poster={/publications/meode/poster.pdf},
  //video={https://youtu.be/Nmum5urconQ}, 
  //code={https://github.com/JurijsNazarovs/panel_me_ode},

}

@inproceedings{meode,
    abbr={UAI},
    %teaser={/publications/me_ode2.pdf},
    teaser={/publications/meode/tadpole.gif},
    title = {Mixed Effect Neural ODE: A variational approximation for analyzing the dynamics of panel data},
    author = {Nazarovs, Jurijs and Chakraborty, Rudrasis and  Tasneeyapant, Songwong  and Ravi, Sathya and Singh, Vikas},
    abstract = {   Panel data involving longitudinal measurements of the same set of participants or entities taken over multiple time points is common in studies to understand early childhood development and disease modeling. Deep hybrid models that marry the predictive power of neural networks with physical 
simulators such as differential equations, are starting to drive 
advances in such applications. The task of modeling 
not just the observations/data but the hidden dynamics that are captured by the measurements poses interesting statistical/computational questions. 
We propose a probabilistic model called ME-NODE to incorporate (fixed + random) mixed effects for analyzing such panel data. 
We show that our model can be derived using smooth approximations of SDEs provided by the Wong-Zakai theorem. We then derive Evidence Based Lower Bounds for ME-NODE, and develop (efficient) training algorithms using MC based sampling methods and numerical ODE solvers. 
We demonstrate ME-NODE's utility on tasks
spanning the spectrum from simulations and toy datasets to real longitudinal 3D imaging data from an Alzheimer's disease (AD) study, and study the performance for accuracy of reconstruction 
for interpolation, uncertainty estimates and personalized prediction.},
  year = {2021},
  //confname={Thirty-seventh Conference on Uncertainty in Artificial Intelligence},
  acceptrate={26},
  month = {May},
  //arxiv={https://arxiv.org/pdf/2202.09478.pdf},
  pdf={https://arxiv.org/pdf/2202.09463.pdf},
  //pdf={/publications/meode/main.pdf},
  //supp={adios-icml16-supp.pdf},
  poster={/publications/meode/poster.pdf},
  video={https://youtu.be/Nmum5urconQ},
  code={https://github.com/JurijsNazarovs/panel_me_ode},

}

@inproceedings{mcrepar,
    abbr={UAI},
    teaser={/publications/mcrepar/graph.gif},
    title = {Graph reparameterizations for enabling 1000+ monte carlo iterations in bayesian deep neural networks},
    author = {Nazarovs, Jurijs and Mehta, Ronak R. and Lokhande, Vishnu Suresh and Singh, Vikas},
    abstract = {    Uncertainty estimation in deep models 
    is essential in many real-world applications and has benefited 
    from developments over the last several years.  
    Recent evidence  suggests that existing solutions dependent on simple Gaussian formulations may not be sufficient.
    However, moving to other distributions necessitates Monte Carlo (MC) sampling to estimate quantities such as the KL divergence: it could be expensive and scales poorly as the dimensions of both the input data and the model grow. 
    This is directly related to the structure of the computation graph, which can grow linearly as a function of the number of MC samples needed.
    Here, we construct a framework to describe these computation graphs, and identify probability families where the graph size can be independent or only weakly dependent on the number of MC samples.
    These families correspond directly to large classes of distributions.
    Empirically, we can run a much larger number of iterations for MC approximations for larger architectures used in 
    computer vision
    with gains in performance measured in confident accuracy, stability of training, memory and training time.},


  year={2021},
  //confname={Thirty-seventh Conference on Uncertainty in Artificial Intelligence},
  
  acceptrate={26},
  month={May},
  //arxiv={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  //pdf={/publications/mcrepar/main.pdf},
  pdf={https://arxiv.org/pdf/2202.09478.pdf},
  //supp={adios-icml16-supp.pdf},
  poster={/publications/mcrepar/poster.pdf},
  video={https://youtu.be/Vg5La64V9Bs},
  code={https://github.com/JurijsNazarovs/bayesian_nn},
}


