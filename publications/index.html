<!DOCTYPE html> <html lang=""> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Jurijs Nazarovs </title> <meta name="author" content="Jurijs Nazarovs"> <meta name="description" content="For the full list refer to my &lt;a href='https://scholar.google.com/citations?view_op=list_works&amp;hl=en&amp;hl=en&amp;user=A5Y2BL0AAAAJ' target='_blank' style='color: blue;'&gt;Google Scholar page&lt;/a&gt;."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="/publications/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jurijs</span> Nazarovs </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/_pages/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">For the full list refer to my <a href="https://scholar.google.com/citations?view_op=list_works&amp;hl=en&amp;hl=en&amp;user=A5Y2BL0AAAAJ" target="_blank" style="color: blue;" rel="external nofollow noopener">Google Scholar page</a>.</p> </header> <article> <div class="publications"> <h2 class="year">2023</h2> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/fode/fode.png"><img src="/publications/fode/fode.png" width="180" height="100"></a> </div> <div id="fode" class="col-lg-8"> <div class="title">Variational Sampling of Temporal Trajectories</div> <div class="author"> Nazarovs, Jurijs, Huang, Zhichun, Zhen, Xingjian, Pal, Sourav, Chakraborty, Rudrasis, and Singh, Vikas </div> <div class="periodical"> <b>arXiv - 2023</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2403.11418" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> </div> <div class="abstract hidden"> <p>A deterministic temporal process can be determined by its trajectory, an element in the product space of (a) initial condition z_0 ∈Z and (b) transition function f: (Z, T) -&gt; Z often influenced by the control of the underlying dynamical system. Existing methods often model the transition function as a differential equation or as a recurrent neural network. Despite their effectiveness in predicting future measurements, few results have successfully established a method for sampling and statistical inference of trajectories using neural networks, partially due to constraints in the parameterization. In this work, we introduce a mechanism to learn the distribution of trajectories by parameterizing the transition function f explicitly as an element in a function space. Our framework allows efficient synthesis of novel trajectories, while also directly providing a convenient tool for inference, i.e., uncertainty estimation, likelihood evaluations and out of distribution detection for abnormal trajectories. These capabilities can have implications for various downstream tasks, e.g., simulation and evaluation for reinforcement learning.</p> </div> </div> </div> </li></ol> <h2 class="year">2022</h2> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/vqa_amazon/vqa_examples.jpg"><img src="/publications/vqa_amazon/vqa_examples.jpg" width="180" height="100"></a> </div> <div id="vqa_amazon" class="col-lg-8"> <div class="title">Improving Robustness of VQA Models by Adversarial and Mixup Augmentation</div> <div class="author"> Nazarovs, Jurijs, Peng, Xujun, Thattai, Govind, Kumar, Anoop, and Galstyan, Aram </div> <div class="periodical"> <b>arXiv - 2022</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/publications/vqa_amazon/VLM.submission.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Recent multimodal models such as VilBERT and UNITER have shown impressive performance on vision-language tasks such as Visual Question Answering (VQA), Visual Referring expressions, and others. However, those models are still not very robust to subtle variations in textual and/or visual input. To improve model robustness to linguistic variations, here we propose a novel adversarial objective function that incorporates information about the distribution of possible linguistic variations. And to improve model robustness to image manipulation, we propose a new VQA-specific mixup technique which leverages object replacement. We conduct extensive experiments on benchmark datasets and demonstrate the effectiveness of the proposed mitigation methods in improving model robustness.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/wnode/teaser.gif"><img src="/publications/wnode/teaser.gif" width="180" height="100"></a> </div> <div id="img2gif" class="col-lg-8"> <div class="title">Image2Gif: Generating Continuous Realistic Animations with Warping NODEs</div> <div class="author"> Nazarovs, Jurijs, and Huang, Zhichun </div> <div class="periodical"> <b>AI4CC, CVPR - 2022</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2205.04519" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="https://github.com/JurijsNazarovs/warping_node" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="/publications/wnode/poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a> </div> <div class="abstract hidden"> <p> Generating smooth animations from a limited number of sequential observations has a number of applications in vision. For example, it can be used to increase number of frames per second, or generating a new trajectory only based on first and last frames, e.g. a motion of face emotions. Despite the discrete observed data (frames), the problem of generating a new trajectory is a continues problem. In addition, to be perceptually realistic, the domain of an image should not alter drastically through the trajectory of changes. In this paper, we propose a new framework, Warping Neural ODE, for generating a smooth animation (video frame interpolation) in a continuous manner, given two ("farther apart") frames, denoting the start and the end of the animation. The key feature of our framework is utilizing the continuous spatial transformation of the image based on the vector field, derived from a system of differential equations. This allows us to achieve the smoothness and the realism of an animation with infinitely small time steps between the frames. We show the application of our work in generating an animation given two frames, in different training settings, including Generative Adversarial Network (GAN) and with L-2 loss.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/uncertainty_with_rf/rf_1slide.png"><img src="/publications/uncertainty_with_rf/rf_1slide.png" width="180" height="100"></a> </div> <div id="uncertrf" class="col-lg-8"> <div class="title">Understanding Uncertainty Maps in Vision With Statistical Testing</div> <div class="author"> Nazarovs, Jurijs, Huang, Zhichun, Tasneeyapant, Songwong, Chakraborty, Rudrasis, and Singh, Vikas </div> <div class="periodical"> <b>CVPR - 2022</b> <a> (Acceptance Rate: 25%) </a> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="https://github.com/JurijsNazarovs/uncertainty_with_rf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="/publications/uncertainty_with_rf/poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a> <a href="https://youtu.be/WJquexM8E38" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> </div> <div class="abstract hidden"> <p> Quantitative descriptions of confidence intervals and uncertainties of the predictions of a model are needed in many applications in vision and machine learning. Mechanisms that enable this for deep neural network (DNN) models are slowly becoming available, and occasionally, being integrated within production systems. But the literature is sparse in terms of how to perform statistical tests with the uncertainties produced by these overparameterized models. For two models with a similar accuracy profile, is the former model’s uncertainty behavior better in a statistically significant sense compared to the second model? For high resolution images, performing hypothesis tests to generate meaningful actionable information (say, at a user specified significance level 0.05) is difficult but needed in both mission critical settings and elsewhere. In this paper, specifically for uncertainties defined on images, we show how revisiting results from Random Field theory (RFT) when paired with DNN tools (to get around computational hurdles) leads to efficient frameworks that can provide a hypothesis test capabilities, not otherwise available, for uncertainty maps from models used in many vision tasks. We show via many different experiments the viability of this framework.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/radial_spikeslab/teaser.pdf"><img src="/publications/radial_spikeslab/teaser.pdf" width="180" height="100"></a> </div> <div id="radspslab" class="col-lg-8"> <div class="title">Radial Spike and Slab Bayesian Neural Networks for Sparse Data in Ransomware Attacks</div> <div class="author"> Nazarovs, Jurijs, Stokes, Jack W., Turcotte, Melissa, Carroll, Justin, and Grady, Itai </div> <div class="periodical"> <b>arXiv - 2022</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2205.14759" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> </div> <div class="abstract hidden"> <p> </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/ordinal-quadruplet/ordin_quadr.gif"><img src="/publications/ordinal-quadruplet/ordin_quadr.gif" width="180" height="100"></a> </div> <div id="ordinquadr" class="col-lg-8"> <div class="title">Ordinal-Quadruplet: Retrieval of Missing Classes in Ordinal Time Series</div> <div class="author"> Nazarovs, Jurijs, Lumezanu, Cristian, Ren, Qianying, Chen, Yuncong, Mizoguchi, Takehiko, Song, Dongjin, and Chen, Haifeng </div> <div class="periodical"> <b>arXiv - 2022</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2201.09907" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> </div> <div class="abstract hidden"> <p>In this paper, we propose an ordered time series classification framework that is robust against missing classes in the training data, i.e., during testing we can prescribe classes that are missing during training. This framework relies on two main components: (1) our newly proposed ordinal-quadruplet loss, which forces the model to learn latent representation while preserving the ordinal relation among labels, (2) testing procedure, which utilizes the property of latent representation (order preservation). We conduct experiments based on real world multivariate time series data and show the significant improvement in the prediction of missing labels even with 40% of the classes are missing from training. Compared with the well-known triplet loss optimization augmented with interpolation for missing information, in some cases, we nearly double the accuracy.</p> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/meode/tadpole.gif"><img src="/publications/meode/tadpole.gif" width="180" height="100"></a> </div> <div id="meode" class="col-lg-8"> <div class="title">Mixed Effect Neural ODE: A variational approximation for analyzing the dynamics of panel data</div> <div class="author"> Nazarovs, Jurijs, Chakraborty, Rudrasis, Tasneeyapant, Songwong, Ravi, Sathya, and Singh, Vikas </div> <div class="periodical"> <b>UAI - 2021</b> <a> (Acceptance Rate: 26%) </a> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2202.09463.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="https://github.com/JurijsNazarovs/panel_me_ode" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="/publications/meode/poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a> <a href="https://youtu.be/Nmum5urconQ" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> </div> <div class="abstract hidden"> <p> Panel data involving longitudinal measurements of the same set of participants or entities taken over multiple time points is common in studies to understand early childhood development and disease modeling. Deep hybrid models that marry the predictive power of neural networks with physical simulators such as differential equations, are starting to drive advances in such applications. The task of modeling not just the observations/data but the hidden dynamics that are captured by the measurements poses interesting statistical/computational questions. We propose a probabilistic model called ME-NODE to incorporate (fixed + random) mixed effects for analyzing such panel data. We show that our model can be derived using smooth approximations of SDEs provided by the Wong-Zakai theorem. We then derive Evidence Based Lower Bounds for ME-NODE, and develop (efficient) training algorithms using MC based sampling methods and numerical ODE solvers. We demonstrate ME-NODE’s utility on tasks spanning the spectrum from simulations and toy datasets to real longitudinal 3D imaging data from an Alzheimer’s disease (AD) study, and study the performance for accuracy of reconstruction for interpolation, uncertainty estimates and personalized prediction.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-lg-3 teas"> <a href="/publications/mcrepar/graph.gif"><img src="/publications/mcrepar/graph.gif" width="180" height="100"></a> </div> <div id="mcrepar" class="col-lg-8"> <div class="title">Graph reparameterizations for enabling 1000+ monte carlo iterations in bayesian deep neural networks</div> <div class="author"> Nazarovs, Jurijs, Mehta, Ronak R., Lokhande, Vishnu Suresh, and Singh, Vikas </div> <div class="periodical"> <b>UAI - 2021</b> <a> (Acceptance Rate: 26%) </a> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2202.09478.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="https://github.com/JurijsNazarovs/bayesian_nn" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="/publications/mcrepar/poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a> <a href="https://youtu.be/Vg5La64V9Bs" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> </div> <div class="abstract hidden"> <p> Uncertainty estimation in deep models is essential in many real-world applications and has benefited from developments over the last several years. Recent evidence suggests that existing solutions dependent on simple Gaussian formulations may not be sufficient. However, moving to other distributions necessitates Monte Carlo (MC) sampling to estimate quantities such as the KL divergence: it could be expensive and scales poorly as the dimensions of both the input data and the model grow. This is directly related to the structure of the computation graph, which can grow linearly as a function of the number of MC samples needed. Here, we construct a framework to describe these computation graphs, and identify probability families where the graph size can be independent or only weakly dependent on the number of MC samples. These families correspond directly to large classes of distributions. Empirically, we can run a much larger number of iterations for MC approximations for larger architectures used in computer vision with gains in performance measured in confident accuracy, stability of training, memory and training time.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Jurijs Nazarovs. Last updated: August 01, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>